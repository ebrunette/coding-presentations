{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68891952",
   "metadata": {},
   "source": [
    "This code leverages data from this kaggle competition. <br>\n",
    "[Real Estate Price Predictions](https://www.kaggle.com/datasets/quantbruce/real-estate-price-prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0c6b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies as needed:\n",
    "# pip install kagglehub[pandas-datasets]\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62a4ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set the path to the file you'd like to load\n",
    "file_path = \"Real estate.csv\"\n",
    "\n",
    "# Load the latest version\n",
    "df = kagglehub.load_dataset(\n",
    "  KaggleDatasetAdapter.PANDAS,\n",
    "  \"quantbruce/real-estate-price-prediction\",\n",
    "  file_path,\n",
    "  pandas_kwargs={\"index_col\": 'No'}\n",
    "  # Provide any additional arguments like \n",
    "  # sql_query or pandas_kwargs. See the \n",
    "  # documenation for more information:\n",
    "  # https://github.com/Kaggle/kagglehub/blob/main/README.md#kaggledatasetadapterpandas\n",
    ")\n",
    "\n",
    "print(\"First 5 records:\", df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd76b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fb5aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a04aea6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1539b38d",
   "metadata": {},
   "source": [
    "# Investigation of the data.\n",
    "Given that I want to figure out price of a house based on the location, a regression based algorithm doesn't make sense. So, we will investigate various clustering options for this dataset and see how things work. <br>\n",
    "\n",
    "The cluster algorithms that we use is based on the patterns in the data that we notice, size of the dataset, etc. So, given these factors we will need to know the following before choose the appropriate cluster algorithm. <br>\n",
    "\n",
    "1. This isn't a large dataset (414 rows) so various models that require a large dataset likely won't perform very well, unless we generate data. \n",
    "2. The documentation for this dataset is very lacking. So, we should do a little digging on some of this information to determine what we are dealing with. \n",
    "3. There isn't any missing data in this dataset (HUGE PLUS because we don't have to deal with nulls). However, we don't have a ton of features that we can play with, is there any features that we can generate or expand from this dataset that we can leverage? \n",
    "4. What is the distribution of the prices? (It is common to have some outliars when dealing with numbers wihtout a cap. So, how might we handle this?)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5c8e7c",
   "metadata": {},
   "source": [
    "Number one above was more of a statement and not something to investigate, but it does affect our end decision. <br>\n",
    "So, I am going to start with investigating #2. <br>\n",
    "Exploring some basic information about this class, it looks like these coordinates are in Taipei City. This affects currency and various other factors of this dataset as there isn't any additional data to this dataset. However, we can still do analysis on this dataset and I am hoping to cover other concepts around this that can be applied to other datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf18ce0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Assume df is your housing dataset\n",
    "features = [\"X1 transaction date\",\n",
    "            \"X2 house age\",\n",
    "            \"X3 distance to the nearest MRT station\",\n",
    "            \"X4 number of convenience stores\",\n",
    "            \"X5 latitude\",\n",
    "            \"X6 longitude\"]\n",
    "X = df[features]\n",
    "\n",
    "# Standardize\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply KMeans\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "df['cluster'] = kmeans.fit_predict(X_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f451fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "df['pca1'], df['pca2'] = X_pca[:, 0], X_pca[:, 1]\n",
    "\n",
    "plt.scatter(df['pca1'], df['pca2'], c=df['cluster'], cmap='viridis')\n",
    "plt.xlabel('PCA 1')\n",
    "plt.ylabel('PCA 2')\n",
    "plt.title('Housing Clusters')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b05a77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "print(pca.explained_variance_ratio_)\n",
    "\n",
    "loadings = pd.DataFrame(\n",
    "    pca.components_.T,\n",
    "    columns=['PCA1', 'PCA2'],\n",
    "    index=features\n",
    ")\n",
    "\n",
    "print(loadings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c881b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca = pd.DataFrame(X_pca, columns=['PCA1', 'PCA2'])\n",
    "df_pca['price'] = df['Y house price of unit area']  # append price\n",
    "\n",
    "# Compute correlations\n",
    "correlations = df_pca.corr()\n",
    "print(correlations['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5d6d60",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
